{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0791594",
   "metadata": {},
   "source": [
    "### Imports and device for Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import  torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from  torchvision.models import mobilenet_v2, MobileNet_V2_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "4057f0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"The device is:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da18ba",
   "metadata": {},
   "source": [
    "### Task 1: Prepare Data Subset\n",
    "- Use the CIFAR-10 training set and construct a balanced subset with 1000 images per class (total = 10,000 images).\n",
    "- To download the dataset, you may use following two packages in Pytorch: import torch, torchvision in the beginning of the code, and you can refer to following code to download the training set and testing set of the dataset:\n",
    "    - full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    - testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "- After download and load the dataset, you will need to write you own code to make sure each class has 1000 images randomly selected from the whole training set for training. Testing set remain the same as the original dataset test set.\n",
    "- Use a fixed random seed to ensure reproducibility.\n",
    "- Verify that each class has the correct number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x117a30210>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Set random seed\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a1c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [02:59<00:00, 950kB/s]  \n"
     ]
    }
   ],
   "source": [
    "# 2. Transformation of CIFAR 10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 3. Downloading the dataset\n",
    "full_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d02558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Select 1000 samples per class\n",
    "\n",
    "# Dictionary to hold indices per class\n",
    "# CIFAR 10 has 10 unique classes\n",
    "class_indices = {i: [] for i in range(10)}  \n",
    "\n",
    "# Iterate through dataset and collect indices for each class\n",
    "for idx, (_, label) in enumerate(full_trainset):\n",
    "    if len(class_indices[label]) < 1000:\n",
    "        class_indices[label].append(idx)\n",
    "\n",
    "    # Stop iteration if all classes collected 1000 samples\n",
    "    if all(len(v) == 1000 for v in class_indices.values()):\n",
    "        break\n",
    "\n",
    "# Flatten the list of indices to create a subset\n",
    "selected_indices = [idx for indices in class_indices.values() for idx in indices]\n",
    "\n",
    "# Create a subset dataset\n",
    "subset_trainset = Subset(full_trainset, selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "dc5f488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in subset: Counter({0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000})\n",
      "Total subset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# 5. Verify class distribution\n",
    "subset_targets = [full_trainset.targets[i] for i in selected_indices]\n",
    "print(\"Class distribution in subset:\", Counter(subset_targets))\n",
    "print(\"Total subset size:\", len(subset_trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ec879b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Setting data and target variables for further use in training and testing model\n",
    "# Training dataset\n",
    "trainset_target = np.array([full_trainset.targets[i] for i in selected_indices])\n",
    "trainset_data = np.array([full_trainset.data[i] for i in selected_indices])\n",
    "\n",
    "# Test dataset\n",
    "testset_target = testset.targets\n",
    "testset_data = testset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d96c0",
   "metadata": {},
   "source": [
    "### Task 2: Implement a Custom CNN\n",
    "- Design a custom CNN model using at least 3 convolutional layers.\n",
    "- Use ReLU activation, pooling, and optionally batch normalization or dropout.\n",
    "- Structure your model cleanly and modularly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "2998e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        # First convolution layer\n",
    "        nn.Conv2d(3, 32, kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "\n",
    "        # Second convolution layer\n",
    "        nn.Conv2d(32, 64, kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "\n",
    "        # Third convolution layer\n",
    "        nn.Conv2d(64, 128, kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "\n",
    "        # Fully connected layer\n",
    "        nn.Flatten(),\n",
    "\n",
    "        # Output layer\n",
    "        nn.Linear(512, 10)\n",
    "    ).to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "d857dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 32, 30, 30]          896\n",
      "├─ReLU: 1-2                              [-1, 32, 30, 30]          --\n",
      "├─MaxPool2d: 1-3                         [-1, 32, 15, 15]          --\n",
      "├─Conv2d: 1-4                            [-1, 64, 13, 13]          18,496\n",
      "├─ReLU: 1-5                              [-1, 64, 13, 13]          --\n",
      "├─MaxPool2d: 1-6                         [-1, 64, 6, 6]            --\n",
      "├─Conv2d: 1-7                            [-1, 128, 4, 4]           73,856\n",
      "├─ReLU: 1-8                              [-1, 128, 4, 4]           --\n",
      "├─MaxPool2d: 1-9                         [-1, 128, 2, 2]           --\n",
      "├─Flatten: 1-10                          [-1, 512]                 --\n",
      "├─Linear: 1-11                           [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 98,378\n",
      "Trainable params: 98,378\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 5.08\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.32\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 0.70\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "summary(model, (3, 32,32));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5cf87",
   "metadata": {},
   "source": [
    "### Task 3: Load and Adapt MobileNetV2\n",
    "- Load a pretrained MobileNetV2 from torchvision.models.\n",
    "- Modify the classifier to output 10 classes (CIFAR-10).\n",
    "- Properly initialize the classifier layer and allow appropriate fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "5d916351",
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2_model = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "# Since CIFAR 10 has 10 classes, we need to modify the classifier output to 10\n",
    "\n",
    "'''\n",
    "# Method - 1\n",
    "# 1. Get the input features of the classifier\n",
    "# 2. then replace with a new Linear layer for 10 classes\n",
    "'''\n",
    "in_features = MobileNetV2_model.classifier[1].in_features \n",
    "MobileNetV2_model.classifier[1] = nn.Linear(in_features, 10) \n",
    "\n",
    "# Method - 2\n",
    "# MobileNetV2_model.classifier[1].out_features = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "e9832ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning the MobileNetV2 model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "3e8ce5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, images, targets):\n",
    "        images = torch.tensor(images)\n",
    "        images = images.float()/255\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.targets[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "32de3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    train = CIFAR10Dataset(trainset_data, trainset_target)\n",
    "    train_dl = DataLoader(train, batch_size=1000, shuffle=True)\n",
    "    return train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3d9d98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    test = CIFAR10Dataset(testset_data, testset_target)\n",
    "    test_dl = DataLoader(test, batch_size=1000, shuffle=True)\n",
    "    return test_dl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp3420",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
